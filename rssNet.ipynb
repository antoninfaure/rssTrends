{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\cupy\\_environment.py:213: UserWarning: CUDA path could not be detected. Set CUDA_PATH environment variable if CuPy fails to load.\n",
      "  warnings.warn(\n",
      "c:\\Users\\anton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\cupy\\_environment.py:213: UserWarning: CUDA path could not be detected. Set CUDA_PATH environment variable if CuPy fails to load.\n",
      "  warnings.warn(\n",
      "c:\\Users\\anton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\anton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\cupy\\_environment.py:213: UserWarning: CUDA path could not be detected. Set CUDA_PATH environment variable if CuPy fails to load.\n",
      "  warnings.warn(\n",
      "c:\\Users\\anton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\cupy\\_environment.py:213: UserWarning: CUDA path could not be detected. Set CUDA_PATH environment variable if CuPy fails to load.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import sys\n",
    "from unicodedata import category\n",
    "import json\n",
    "import os\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from datetime import date, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_urls = [\n",
    "    \"http://www.lemonde.fr/rss/une.xml\",\n",
    "    \"https://www.bfmtv.com/rss/news-24-7/\",\n",
    "    \"https://www.liberation.fr/rss/\",\n",
    "    \"http://www.lefigaro.fr/rss/figaro_actualites.xml\",\n",
    "    \"https://www.franceinter.fr/rss\",\n",
    "    \"https://www.lexpress.fr/arc/outboundfeeds/rss/alaune.xml\",\n",
    "    \"https://www.francetvinfo.fr/titres.rss\",\n",
    "    \"https://www.la-croix.com/RSS\",\n",
    "    \"http://tempsreel.nouvelobs.com/rss.xml\",\n",
    "    \"http://www.lepoint.fr/rss.xml\",\n",
    "    \"https://www.france24.com/fr/rss\",\n",
    "    \"https://feeds.leparisien.fr/leparisien/rss\",\n",
    "    \"https://www.ouest-france.fr/rss/une\",\n",
    "    \"https://www.europe1.fr/rss.xml\",\n",
    "    \"https://partner-feeds.20min.ch/rss/20minutes\",\n",
    "    \"https://www.afp.com/fr/actus/afp_actualite/792,31,9,7,33/feed\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap(feed_urls):\n",
    "    news_list = pd.DataFrame(columns=('title', 'summary'))\n",
    "\n",
    "    for feed_url in feed_urls:\n",
    "        res = requests.get(feed_url)\n",
    "        feed = BeautifulSoup(res.content, features='xml')\n",
    "\n",
    "        articles = feed.findAll('item')       \n",
    "        for article in articles:\n",
    "            title = BeautifulSoup(article.find('title').get_text(), \"html\").get_text()\n",
    "            summary = \"\"\n",
    "            if (article.find('description')):\n",
    "                summary = BeautifulSoup(article.find('description').get_text(), \"html\").get_text()\n",
    "            news_list.loc[len(news_list)] = [title, summary]\n",
    "\n",
    "    return news_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(docs, lang='fr'):\n",
    "    if (lang=='fr'):\n",
    "        nlp = spacy.load('fr_core_news_lg')\n",
    "    elif (lang=='en'):\n",
    "        nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "    # Utility functions\n",
    "    punctuation_chars =  [\n",
    "        chr(i) for i in range(sys.maxunicode)\n",
    "        if category(chr(i)).startswith(\"P\")\n",
    "    ]\n",
    "    \n",
    "    lemma_docs = []\n",
    "    for doc in docs:\n",
    "        # Tokenize docs\n",
    "        tokenized_doc = nlp(doc)\n",
    "\n",
    "        # Lemmanize docs\n",
    "        lemma_doc = list(filter(lambda token: token.is_stop == False and token.pos_ in ['NOUN', 'PROPN','ADJ'] and token.lemma_ not in [*string.punctuation, *punctuation_chars], tokenized_doc))\n",
    "        lemma_doc = list(map(lambda tok: tok.lemma_, lemma_doc))\n",
    "        lemma_docs.append(lemma_doc)\n",
    "\n",
    "\n",
    "    def get_vocabulary_frequency(documents):\n",
    "        vocabulary = dict()\n",
    "        for doc in documents:\n",
    "            for word in doc:\n",
    "                if word in list(vocabulary.keys()):\n",
    "                    vocabulary[word] += 1\n",
    "                else:\n",
    "                    vocabulary[word] = 1\n",
    "\n",
    "        return vocabulary\n",
    "\n",
    "    voc = get_vocabulary_frequency(lemma_docs)\n",
    "\n",
    "    return lemma_docs, voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graphnet(docs, voc, min_freq=5):\n",
    "    \n",
    "    # Filter voc with min_freq\n",
    "    filtered_voc = dict(filter(lambda elem: elem[1] > min_freq, voc.items()))\n",
    "\n",
    "    dict_voc_id = dict()\n",
    "    for i, term in enumerate(filtered_voc):\n",
    "        dict_voc_id[term] = i\n",
    "    \n",
    "    # List bigrams (edges)\n",
    "    finder = nltk.BigramCollocationFinder.from_documents(docs)\n",
    "    bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "    bigrams = list(finder.score_ngrams(bigram_measures.raw_freq))\n",
    "    min_freq = min(list(map(lambda x: x[1], bigrams)))\n",
    "    bigrams = list(map(lambda x: (x[0], x[1]/min_freq), bigrams))\n",
    "\n",
    "    # Filter the bigrams with filtered_voc elements and replace by id\n",
    "    filtered_bigrams = []\n",
    "    for bigram in bigrams:\n",
    "        if (bigram[0][0] in filtered_voc.keys() and bigram[0][1] in filtered_voc.keys()):\n",
    "            new_bigram = ( dict_voc_id[bigram[0][0]] , dict_voc_id[bigram[0][1]] )\n",
    "            filtered_bigrams.append((new_bigram, bigram[1]))\n",
    "\n",
    "    # Set nodes sizes\n",
    "    sizes = list(filtered_voc.values())\n",
    "\n",
    "    # Format data\n",
    "    nodes = []\n",
    "    for i, term in enumerate(filtered_voc.keys()):\n",
    "        nodes.append({\n",
    "            'id': i,\n",
    "            'label': term,\n",
    "            'size': sizes[i]\n",
    "        })\n",
    "    \n",
    "    edges = []\n",
    "    for i, edge in enumerate(filtered_bigrams):\n",
    "        (source, target) = edge[0]\n",
    "        edges.append({\n",
    "            'id': i,\n",
    "            'source': source,\n",
    "            'target': target,\n",
    "            'size': edge[1]\n",
    "        })\n",
    "\n",
    "    \n",
    "    # Write JSON files\n",
    "    output_file(nodes, 'nodes.json')\n",
    "\n",
    "    \n",
    "    output_file(edges, 'edges.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_file(data, filename):\n",
    "    path = f'./data/{date.today().strftime(\"%d-%m-%Y\")}'\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    with open(f'{path}/{filename}', 'w', encoding='UTF8', newline='') as f:\n",
    "        writer = json.dump(data, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bs4\\__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "c:\\Users\\anton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bs4\\__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "c:\\Users\\anton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bs4\\__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "c:\\Users\\anton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bs4\\__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "c:\\Users\\anton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bs4\\__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "c:\\Users\\anton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bs4\\__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "c:\\Users\\anton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bs4\\__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "c:\\Users\\anton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bs4\\__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "c:\\Users\\anton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bs4\\__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "c:\\Users\\anton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bs4\\__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "news_list = scrap(feed_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs, voc = process_text(news_list['title'], lang='fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphnet(docs, voc, min_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_trends(docs, criterion='leverage', level=0.01):\n",
    "    te = TransactionEncoder()\n",
    "    te_ary = te.fit(docs).transform(docs, sparse=True)\n",
    "    df = pd.DataFrame.sparse.from_spmatrix(te_ary, columns=te.columns_)\n",
    "\n",
    "    frequent_itemsets = apriori(df, min_support=0.005, use_colnames=True, verbose=1)\n",
    "    frequent_itemsets['length'] = frequent_itemsets['itemsets'].apply(lambda x: len(x))\n",
    "\n",
    "    rules = association_rules(frequent_itemsets, metric =\"lift\", min_threshold = 1)\n",
    "    rules = rules.sort_values([criterion], ascending =[False])\n",
    "\n",
    "    rules = rules[rules[criterion] > level]\n",
    "\n",
    "    trends = []\n",
    "    for i in rules.index:\n",
    "        rule = rules.loc[i]\n",
    "        x = list(rule['antecedents'])\n",
    "        y = list(rule['consequents'])\n",
    "        terms = x + y\n",
    "        ok = True\n",
    "        new_trend = terms\n",
    "        delete_trends_ids = []\n",
    "        for term in terms:\n",
    "            for i, trend in enumerate(trends):\n",
    "                if (term in trend):\n",
    "                    ok = False\n",
    "                    old_trend = new_trend\n",
    "                    new_trend = list(set(new_trend + list(trend)))\n",
    "                    #print(f'{old_trend} -> {new_trend}')\n",
    "                    delete_trends_ids.append(i)\n",
    "        if (ok == True):\n",
    "            trends.append((tuple(y + x)))\n",
    "        else:\n",
    "            trends = [x for i, x in enumerate(trends) if i not in delete_trends_ids]\n",
    "            trends.insert(min(delete_trends_ids), tuple(new_trend))\n",
    "    \n",
    "    output_file(trends, 'trends.json')\n",
    "\n",
    "    return trends, rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_dates():\n",
    "    dates = [x for x in next(os.walk('./data'))[1]]\n",
    "    dates.sort(key=lambda date: datetime.strptime(date, \"%d-%m-%Y\"), reverse=True)\n",
    "    dates = [{\"name\": x} for x in dates]\n",
    "    with open(f'./data/list.json', 'w', encoding='UTF8', newline='') as f:\n",
    "        writer = json.dump(dates, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 7 combinations | Sampling itemset size 7 653\n"
     ]
    }
   ],
   "source": [
    "trends, rules = find_trends(docs, 'leverage', 0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>(Palmade)</td>\n",
       "      <td>(Pierre)</td>\n",
       "      <td>0.044776</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.615385</td>\n",
       "      <td>0.042604</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>(Pierre)</td>\n",
       "      <td>(Palmade)</td>\n",
       "      <td>0.044776</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>20.615385</td>\n",
       "      <td>0.042604</td>\n",
       "      <td>12.417910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>(guerre)</td>\n",
       "      <td>(Ukraine)</td>\n",
       "      <td>0.039179</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>16.034188</td>\n",
       "      <td>0.036736</td>\n",
       "      <td>4.938060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>(Ukraine)</td>\n",
       "      <td>(guerre)</td>\n",
       "      <td>0.039179</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>16.034188</td>\n",
       "      <td>0.036736</td>\n",
       "      <td>4.281716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>(accident, Pierre)</td>\n",
       "      <td>(Palmade)</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>22.333333</td>\n",
       "      <td>0.028514</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>(Palmade)</td>\n",
       "      <td>(accident, Pierre)</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>22.333333</td>\n",
       "      <td>0.028514</td>\n",
       "      <td>2.910448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>(accident)</td>\n",
       "      <td>(Palmade, Pierre)</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>21.019608</td>\n",
       "      <td>0.028431</td>\n",
       "      <td>16.238806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>(accident)</td>\n",
       "      <td>(Palmade)</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>21.019608</td>\n",
       "      <td>0.028431</td>\n",
       "      <td>16.238806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>(Palmade)</td>\n",
       "      <td>(accident)</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>21.019608</td>\n",
       "      <td>0.028431</td>\n",
       "      <td>2.904851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>(Palmade, Pierre)</td>\n",
       "      <td>(accident)</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>21.019608</td>\n",
       "      <td>0.028431</td>\n",
       "      <td>2.904851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>(accident, Palmade)</td>\n",
       "      <td>(Pierre)</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.615385</td>\n",
       "      <td>0.028403</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>(Pierre)</td>\n",
       "      <td>(accident, Palmade)</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>20.615385</td>\n",
       "      <td>0.028403</td>\n",
       "      <td>2.522388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>(accident)</td>\n",
       "      <td>(Pierre)</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>19.402715</td>\n",
       "      <td>0.028312</td>\n",
       "      <td>16.175373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>(Pierre)</td>\n",
       "      <td>(accident)</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>19.402715</td>\n",
       "      <td>0.028312</td>\n",
       "      <td>2.517537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>(retraite)</td>\n",
       "      <td>(réforme)</td>\n",
       "      <td>0.026119</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>18.482759</td>\n",
       "      <td>0.024706</td>\n",
       "      <td>1.882836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             antecedents          consequents   support  confidence  \\\n",
       "86             (Palmade)             (Pierre)  0.044776    1.000000   \n",
       "87              (Pierre)            (Palmade)  0.044776    0.923077   \n",
       "152             (guerre)            (Ukraine)  0.039179    0.807692   \n",
       "153            (Ukraine)             (guerre)  0.039179    0.777778   \n",
       "467   (accident, Pierre)            (Palmade)  0.029851    1.000000   \n",
       "470            (Palmade)   (accident, Pierre)  0.029851    0.666667   \n",
       "469           (accident)    (Palmade, Pierre)  0.029851    0.941176   \n",
       "88            (accident)            (Palmade)  0.029851    0.941176   \n",
       "89             (Palmade)           (accident)  0.029851    0.666667   \n",
       "468    (Palmade, Pierre)           (accident)  0.029851    0.666667   \n",
       "466  (accident, Palmade)             (Pierre)  0.029851    1.000000   \n",
       "471             (Pierre)  (accident, Palmade)  0.029851    0.615385   \n",
       "106           (accident)             (Pierre)  0.029851    0.941176   \n",
       "107             (Pierre)           (accident)  0.029851    0.615385   \n",
       "286           (retraite)            (réforme)  0.026119    0.482759   \n",
       "\n",
       "          lift  leverage  conviction  \n",
       "86   20.615385  0.042604         inf  \n",
       "87   20.615385  0.042604   12.417910  \n",
       "152  16.034188  0.036736    4.938060  \n",
       "153  16.034188  0.036736    4.281716  \n",
       "467  22.333333  0.028514         inf  \n",
       "470  22.333333  0.028514    2.910448  \n",
       "469  21.019608  0.028431   16.238806  \n",
       "88   21.019608  0.028431   16.238806  \n",
       "89   21.019608  0.028431    2.904851  \n",
       "468  21.019608  0.028431    2.904851  \n",
       "466  20.615385  0.028403         inf  \n",
       "471  20.615385  0.028403    2.522388  \n",
       "106  19.402715  0.028312   16.175373  \n",
       "107  19.402715  0.028312    2.517537  \n",
       "286  18.482759  0.024706    1.882836  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules.head(15)[['antecedents', 'consequents', 'support', 'confidence', 'lift', 'leverage', 'conviction']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Pradié',\n",
       " 'LR',\n",
       " 'médecin',\n",
       " 'âge',\n",
       " 'cotisation',\n",
       " 'SNCF',\n",
       " 'février',\n",
       " 'an',\n",
       " 'jeudi',\n",
       " 'Aurélien',\n",
       " 'RATP',\n",
       " 'enfant',\n",
       " 'perturbation',\n",
       " 'libéral',\n",
       " 'majorité',\n",
       " 'carrière',\n",
       " 'grève',\n",
       " 'réforme',\n",
       " 'long',\n",
       " 'retraite')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trends[2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f93075eebf97bc5e18c38d1a54e461de353c7365fd9def5e44782928585336f0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
